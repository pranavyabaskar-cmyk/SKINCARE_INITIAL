{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a39aaed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"product_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9707ad21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows, Columns: (8494, 27)\n",
      "\n",
      "Columns:\n",
      " ['product_id', 'product_name', 'brand_id', 'brand_name', 'loves_count', 'rating', 'reviews', 'size', 'variation_type', 'variation_value', 'variation_desc', 'ingredients', 'price_usd', 'value_price_usd', 'sale_price_usd', 'limited_edition', 'new', 'online_only', 'out_of_stock', 'sephora_exclusive', 'highlights', 'primary_category', 'secondary_category', 'tertiary_category', 'child_count', 'child_max_price', 'child_min_price']\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows, Columns:\", df.shape)\n",
    "print(\"\\nColumns:\\n\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c4610e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>brand_id</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>loves_count</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviews</th>\n",
       "      <th>size</th>\n",
       "      <th>variation_type</th>\n",
       "      <th>variation_value</th>\n",
       "      <th>...</th>\n",
       "      <th>online_only</th>\n",
       "      <th>out_of_stock</th>\n",
       "      <th>sephora_exclusive</th>\n",
       "      <th>highlights</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>secondary_category</th>\n",
       "      <th>tertiary_category</th>\n",
       "      <th>child_count</th>\n",
       "      <th>child_max_price</th>\n",
       "      <th>child_min_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P473671</td>\n",
       "      <td>Fragrance Discovery Set</td>\n",
       "      <td>6342</td>\n",
       "      <td>19-69</td>\n",
       "      <td>6320</td>\n",
       "      <td>3.6364</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['Unisex/ Genderless Scent', 'Warm &amp;Spicy Scen...</td>\n",
       "      <td>Fragrance</td>\n",
       "      <td>Value &amp; Gift Sets</td>\n",
       "      <td>Perfume Gift Sets</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P473668</td>\n",
       "      <td>La Habana Eau de Parfum</td>\n",
       "      <td>6342</td>\n",
       "      <td>19-69</td>\n",
       "      <td>3827</td>\n",
       "      <td>4.1538</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.4 oz/ 100 mL</td>\n",
       "      <td>Size + Concentration + Formulation</td>\n",
       "      <td>3.4 oz/ 100 mL</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['Unisex/ Genderless Scent', 'Layerable Scent'...</td>\n",
       "      <td>Fragrance</td>\n",
       "      <td>Women</td>\n",
       "      <td>Perfume</td>\n",
       "      <td>2</td>\n",
       "      <td>85.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P473662</td>\n",
       "      <td>Rainbow Bar Eau de Parfum</td>\n",
       "      <td>6342</td>\n",
       "      <td>19-69</td>\n",
       "      <td>3253</td>\n",
       "      <td>4.2500</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.4 oz/ 100 mL</td>\n",
       "      <td>Size + Concentration + Formulation</td>\n",
       "      <td>3.4 oz/ 100 mL</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['Unisex/ Genderless Scent', 'Layerable Scent'...</td>\n",
       "      <td>Fragrance</td>\n",
       "      <td>Women</td>\n",
       "      <td>Perfume</td>\n",
       "      <td>2</td>\n",
       "      <td>75.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P473660</td>\n",
       "      <td>Kasbah Eau de Parfum</td>\n",
       "      <td>6342</td>\n",
       "      <td>19-69</td>\n",
       "      <td>3018</td>\n",
       "      <td>4.4762</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.4 oz/ 100 mL</td>\n",
       "      <td>Size + Concentration + Formulation</td>\n",
       "      <td>3.4 oz/ 100 mL</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['Unisex/ Genderless Scent', 'Layerable Scent'...</td>\n",
       "      <td>Fragrance</td>\n",
       "      <td>Women</td>\n",
       "      <td>Perfume</td>\n",
       "      <td>2</td>\n",
       "      <td>75.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P473658</td>\n",
       "      <td>Purple Haze Eau de Parfum</td>\n",
       "      <td>6342</td>\n",
       "      <td>19-69</td>\n",
       "      <td>2691</td>\n",
       "      <td>3.2308</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.4 oz/ 100 mL</td>\n",
       "      <td>Size + Concentration + Formulation</td>\n",
       "      <td>3.4 oz/ 100 mL</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['Unisex/ Genderless Scent', 'Layerable Scent'...</td>\n",
       "      <td>Fragrance</td>\n",
       "      <td>Women</td>\n",
       "      <td>Perfume</td>\n",
       "      <td>2</td>\n",
       "      <td>75.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_id               product_name  brand_id brand_name  loves_count  \\\n",
       "0    P473671    Fragrance Discovery Set      6342      19-69         6320   \n",
       "1    P473668    La Habana Eau de Parfum      6342      19-69         3827   \n",
       "2    P473662  Rainbow Bar Eau de Parfum      6342      19-69         3253   \n",
       "3    P473660       Kasbah Eau de Parfum      6342      19-69         3018   \n",
       "4    P473658  Purple Haze Eau de Parfum      6342      19-69         2691   \n",
       "\n",
       "   rating  reviews            size                      variation_type  \\\n",
       "0  3.6364     11.0             NaN                                 NaN   \n",
       "1  4.1538     13.0  3.4 oz/ 100 mL  Size + Concentration + Formulation   \n",
       "2  4.2500     16.0  3.4 oz/ 100 mL  Size + Concentration + Formulation   \n",
       "3  4.4762     21.0  3.4 oz/ 100 mL  Size + Concentration + Formulation   \n",
       "4  3.2308     13.0  3.4 oz/ 100 mL  Size + Concentration + Formulation   \n",
       "\n",
       "  variation_value  ... online_only out_of_stock  sephora_exclusive  \\\n",
       "0             NaN  ...           1            0                  0   \n",
       "1  3.4 oz/ 100 mL  ...           1            0                  0   \n",
       "2  3.4 oz/ 100 mL  ...           1            0                  0   \n",
       "3  3.4 oz/ 100 mL  ...           1            0                  0   \n",
       "4  3.4 oz/ 100 mL  ...           1            0                  0   \n",
       "\n",
       "                                          highlights  primary_category  \\\n",
       "0  ['Unisex/ Genderless Scent', 'Warm &Spicy Scen...         Fragrance   \n",
       "1  ['Unisex/ Genderless Scent', 'Layerable Scent'...         Fragrance   \n",
       "2  ['Unisex/ Genderless Scent', 'Layerable Scent'...         Fragrance   \n",
       "3  ['Unisex/ Genderless Scent', 'Layerable Scent'...         Fragrance   \n",
       "4  ['Unisex/ Genderless Scent', 'Layerable Scent'...         Fragrance   \n",
       "\n",
       "   secondary_category  tertiary_category  child_count  child_max_price  \\\n",
       "0   Value & Gift Sets  Perfume Gift Sets            0              NaN   \n",
       "1               Women            Perfume            2             85.0   \n",
       "2               Women            Perfume            2             75.0   \n",
       "3               Women            Perfume            2             75.0   \n",
       "4               Women            Perfume            2             75.0   \n",
       "\n",
       "   child_min_price  \n",
       "0              NaN  \n",
       "1             30.0  \n",
       "2             30.0  \n",
       "3             30.0  \n",
       "4             30.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head(5))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a7f185a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primary category value counts:\n",
      " primary_category_clean\n",
      "skincare           2420\n",
      "makeup             2369\n",
      "hair               1464\n",
      "fragrance          1432\n",
      "bath & body         405\n",
      "mini size           288\n",
      "men                  60\n",
      "tools & brushes      52\n",
      "gifts                 4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample parsed highlights (first 10 rows):\n",
      "1 ['Unisex/ Genderless Scent', 'Warm &Spicy Scent', 'Woody & Earthy Scent', 'Fresh Scent']\n",
      "2 ['Unisex/ Genderless Scent', 'Layerable Scent', 'Warm &Spicy Scent']\n",
      "3 ['Unisex/ Genderless Scent', 'Layerable Scent', 'Woody & Earthy Scent']\n",
      "4 ['Unisex/ Genderless Scent', 'Layerable Scent', 'Warm &Spicy Scent']\n",
      "5 ['Unisex/ Genderless Scent', 'Layerable Scent', 'Woody & Earthy Scent']\n",
      "6 ['Warm &Spicy Scent', 'Unisex/ Genderless Scent', 'Layerable Scent']\n",
      "7 ['Unisex/ Genderless Scent', 'Layerable Scent', 'Woody & Earthy Scent']\n",
      "8 ['Unisex/ Genderless Scent', 'allure 2022 Best of Beauty Award Winner', 'Fresh Scent']\n",
      "9 ['Fresh Scent', 'Layerable Scent', 'Unisex/ Genderless Scent']\n",
      "10 ['Unisex/ Genderless Scent', 'allure 2022 Best of Beauty Award Winner', 'Fresh Scent']\n",
      "\n",
      "Top 30 tags in highlights (tag : count):\n",
      "Vegan : 2623\n",
      "Cruelty-Free : 1775\n",
      "Clean at Sephora : 1534\n",
      "Without Parabens : 1414\n",
      "Good for: Dryness : 1221\n",
      "Hydrating : 1170\n",
      "Good for: Dullness/Uneven Texture : 913\n",
      "Without Sulfates SLS & SLES : 818\n",
      "All Hair Types : 763\n",
      "Long-wearing : 715\n",
      "Clean + Planet Positive : 713\n",
      "Good for: Anti-Aging : 655\n",
      "Hyaluronic Acid : 592\n",
      "Without Phthalates : 586\n",
      "Best for Dry, Combo, Normal Skin : 499\n",
      "Fragrance Free : 497\n",
      "Good for: Frizz : 459\n",
      "Increases Shine : 435\n",
      "Good for: Loss of firmness : 433\n",
      "Good for: Pores : 419\n",
      "Matte Finish : 415\n",
      "Layerable Scent : 410\n",
      "Best for Oily, Combo, Normal Skin : 398\n",
      "Unisex/ Genderless Scent : 357\n",
      "Without Silicones : 346\n",
      "Natural Finish : 346\n",
      "Floral Scent : 344\n",
      "Good for: Damage : 332\n",
      "Gluten Free : 295\n",
      "Liquid Formula : 259\n",
      "\n",
      "Keeping skincare only â€” rows before: 6287, after filter: 2003\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# turning the primary category to lowercase and removing extra space\n",
    "df['primary_category_clean'] = (\n",
    "    df['primary_category']\n",
    "      .astype(str)\n",
    "      .str.strip()\n",
    "      .str.lower()\n",
    ")\n",
    "\n",
    "# checking for all the classes in primary category\n",
    "pc_counts = df['primary_category_clean'].value_counts(dropna=False)\n",
    "print(\"\\nPrimary category value counts:\\n\", pc_counts)\n",
    "\n",
    "# putting the highlights in a list with string separated commas\n",
    "def safe_parse_list(x):\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if isinstance(x, str):\n",
    "        x = x.strip()\n",
    "        # typical list-like string starts with '['\n",
    "        if x.startswith('[') and x.endswith(']'):\n",
    "            try:\n",
    "                parsed = ast.literal_eval(x)\n",
    "                if isinstance(parsed, (list, tuple)):\n",
    "                    return list(parsed)\n",
    "            except Exception:\n",
    "                pass\n",
    "        # sometimes highlights stored as comma-separated string\n",
    "        if ',' in x:\n",
    "            return [s.strip() for s in x.split(',') if s.strip()]\n",
    "    return [str(x)]\n",
    "df['highlights_parsed'] = df['highlights'].apply(safe_parse_list)\n",
    "\n",
    "# Drop rows where 'highlights_parsed' is empty\n",
    "df = df[df['highlights_parsed'].apply(lambda x: len(x) > 0)].reset_index(drop=True)\n",
    "\n",
    "# printing first 10 rows of highlights\n",
    "sample_highlights = df['highlights_parsed'].head(10).tolist()\n",
    "print(\"\\nSample parsed highlights (first 10 rows):\")\n",
    "for i, hl in enumerate(sample_highlights, 1):\n",
    "    print(i, hl)\n",
    "\n",
    "all_tags = [tag for sub in df['highlights_parsed'] for tag in sub if tag]\n",
    "tag_counts = Counter(all_tags)\n",
    "print(\"\\nTop 30 tags in highlights (tag : count):\")\n",
    "for tag, cnt in tag_counts.most_common(30):\n",
    "    print(f\"{tag} : {cnt}\")\n",
    "\n",
    "# keep only skincare as primary_category\n",
    "skincare_mask = df['primary_category_clean'].str.contains('skincare', na=False)\n",
    "skincare_df = df[skincare_mask].copy()\n",
    "print(f\"\\nKeeping skincare only â€” rows before: {len(df)}, after filter: {len(skincare_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f73cc833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved filtered file => skincare_only.csv\n"
     ]
    }
   ],
   "source": [
    "# save this to an excel file\n",
    "skincare_df.to_csv(\"skincare_only.csv\", index=False)\n",
    "print(\"Saved filtered file => skincare_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93ea6ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"skincare_only.csv\")\n",
    "\n",
    "# Replace NaNs\n",
    "df = df.fillna(\"\")\n",
    "\n",
    "# Normalize numeric features\n",
    "scaler = MinMaxScaler()\n",
    "#convert invalid string to \n",
    "df['rating'] = pd.to_numeric(df['rating'], errors='coerce').fillna(0)\n",
    "df['loves_count'] = pd.to_numeric(df['loves_count'], errors='coerce').fillna(0)\n",
    "df['rating_norm'] = scaler.fit_transform(df[['rating']])\n",
    "df['popularity_norm'] = scaler.fit_transform(df[['loves_count']])\n",
    "df['combined_score'] = 0.7 * df['rating_norm'] + 0.3 * df['popularity_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac27f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b05c69f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows, cols: (2003, 29)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"skincare_only.csv\")   \n",
    "print(\"Rows, cols:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8a59640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P439055 GENIUS Sleeping Collagen Moisturizer ['Vegan', 'Good for: Loss of firmness', 'Collagen', 'Hypoallergenic', 'Without Parabens', 'Best for Dry, Combo, Normal Skin']\n",
      "P421277 GENIUS Liquid Collagen Serum ['Vegan', 'Good for: Loss of firmness', 'Collagen', 'Hypoallergenic', 'Without Parabens', 'Best for Dry, Combo, Normal Skin']\n",
      "P432045 GENIUS Liquid Collagen Lip Treatment ['Vegan', 'Good for: Loss of firmness', 'Plumping', 'Collagen', 'Hypoallergenic', 'Best for Dry, Combo, Normal Skin']\n",
      "P311143 SUBLIME DEFENSE Ultra Lightweight UV Defense Fluid SPF 50 ['Vegan', 'Hypoallergenic', 'UV Protection', 'SPF', 'Best for Dry, Combo, Normal Skin']\n",
      "P384537 GENIUS Ultimate Anti-Aging Cream ['Vegan', 'Collagen', 'Hypoallergenic', 'Good for: Loss of firmness', 'Best for Dry, Combo, Normal Skin']\n",
      "P500716 10 Day Results Kit ['Vegan', 'Good for: Loss of firmness', 'Good for: Dark Circles', 'Collagen', 'Hydrating', 'Good for: Anti-Aging']\n"
     ]
    }
   ],
   "source": [
    "df['highlights_parsed'] = df['highlights'].apply(safe_parse_list)\n",
    "# quick check\n",
    "for i, row in df[['product_id','product_name','highlights_parsed']].head(6).iterrows():\n",
    "    print(row['product_id'], row['product_name'], row['highlights_parsed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a71a70da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values with empty string and string to lower case(normalization)\n",
    "df['tertiary_category_clean'] = df['tertiary_category'].fillna('').astype(str).str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f46e3124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine primary category, sec category, tertairy category , highlights and ingrediants text\n",
    "def join_text_field(x):\n",
    "    if isinstance(x, list):\n",
    "        return ' '.join([str(t) for t in x])\n",
    "    return str(x) if pd.notna(x) else ''\n",
    "\n",
    "df['text_for_tfidf'] = (\n",
    "    df['primary_category_clean'].fillna('') + ' ' +\n",
    "    df['secondary_category'].fillna('') + ' ' +\n",
    "    df['tertiary_category_clean'].fillna('') + ' ' +\n",
    "    df['highlights_parsed'].apply(join_text_field) + ' ' +\n",
    "    df['ingredients'].fillna('').astype(str)\n",
    ").str.replace(r'[\\[\\]]', ' ', regex=True)   #remove list brackets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f0ac59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skincare Moisturizers moisturizers Vegan Good for: Loss of firmness Collagen Hypoallergenic Without Parabens Best for Dry, Combo, Normal Skin  'Collagen (Vegan)*, Water (Aqua, Eau), Ethylhexyl Palmitate, Oryza Sativa (Rice) Bran Extract, Caprylic/Capric Triglyceride, Glycerin, Cetearyl Methicone, Dimethicone, Cetearyl Alcohol, Pyrus Malus (Apple) Fruit Extract, Chlorella Protothecoides Oil, Polyso\n"
     ]
    }
   ],
   "source": [
    "print(df['text_for_tfidf'].iloc[0][:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfa5c766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (2003, 6000)\n"
     ]
    }
   ],
   "source": [
    "#removes stop words and converts all the text into numerical vectors\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=6000, ngram_range=(1,2))\n",
    "tfidf_matrix = tfidf.fit_transform(df['text_for_tfidf'])\n",
    "print(\"TF-IDF matrix shape:\", tfidf_matrix.shape) #shape has n_products, n_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80119f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user input\n",
    "user_preferences = ['vegan', 'oily skin', 'spf']\n",
    "tertiary_category = 'sunscreen' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc496959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_keywords(keywords):\n",
    "    # join all the user prefernce words\n",
    "    return [k.lower() for k in keywords]\n",
    "\n",
    "expanded = expand_keywords(user_preferences)\n",
    "query_text = ' '.join(expanded)\n",
    "if tertiary_category:\n",
    "    query_text += ' ' + str(tertiary_category).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "729434f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize user input\n",
    "user_vec = tfidf.transform([query_text])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee2c157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measures the similarity between the user input and the dataset\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sim_scores = cosine_similarity(user_vec, tfidf_matrix).flatten()  # shape: (n_products,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11532b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map keywords with the user input\n",
    "keyword_map = {\n",
    "    'hydrating': ['hydrating', 'moisturiz', 'moisturizer', 'hydration', 'hydrating'],\n",
    "    'moisturizer': ['moisturizer', 'moisturising', 'moisturizing'],\n",
    "    'sunscreen': ['sunscreen', 'spf', 'sunblock', 'sun protection'],\n",
    "    'anti-aging': ['anti-aging', 'anti age', 'age-defying', 'firming'],\n",
    "    'acne': ['acne', 'blemish', 'breakout', 'anti-acne'],\n",
    "    'oily skin': ['oily skin', 'for oily', 'matte'],\n",
    "    'dry skin': ['dry skin', 'for dry'],\n",
    "    'sensitive skin': ['sensitive', 'hypoallergenic', 'dermatologist'],\n",
    "    'vegan': ['vegan', 'cruelty-free']\n",
    "}\n",
    "\n",
    "def expand_keywords(user_terms):\n",
    "    expanded = []\n",
    "    lowered = [t.lower() for t in user_terms]\n",
    "    for term in lowered:\n",
    "        matched = False\n",
    "        for k, variants in keyword_map.items():\n",
    "            if term in variants or k == term:\n",
    "                expanded.extend(variants)\n",
    "                matched = True\n",
    "                break\n",
    "        if not matched:\n",
    "            expanded.append(term)\n",
    "    # dedupe preserving order\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for t in expanded:\n",
    "        if t not in seen:\n",
    "            out.append(t)\n",
    "            seen.add(t)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68e3f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating_norm'] = scaler.fit_transform(df[['rating']])\n",
    "df['popularity_norm'] = scaler.fit_transform(df[['loves_count']])\n",
    "df['combined_score'] = 0.7 * df['rating_norm'] + 0.3 * df['popularity_norm']\n",
    "\n",
    "sim_weight = 0.7\n",
    "score_weight = 0.3\n",
    "\n",
    "df['sim_score'] = sim_scores\n",
    "df['final_score'] = sim_weight * df['sim_score'] + score_weight * df['combined_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21f7bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = df.copy()\n",
    "\n",
    "price_min = 0       # or None if you don't want a lower limit\n",
    "price_max = 50      # max price filter\n",
    "tertiary_category = 'sunscreen'  # e.g., sunscreen\n",
    "\n",
    "# Tertiary category filter\n",
    "if tertiary_category:\n",
    "    candidates = candidates[\n",
    "        candidates['tertiary_category_clean'].str.contains(tertiary_category.lower(), na=False)\n",
    "    ]\n",
    "\n",
    "# user budget\n",
    "if price_min is not None:\n",
    "    candidates = candidates[candidates['price_usd'] >= price_min]\n",
    "if price_max is not None:\n",
    "    candidates = candidates[candidates['price_usd'] <= price_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10950330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           product_name  rating  price_usd  \\\n",
      "243   Full Spectrum 360Âº Refreshing Water Cream Orga...  4.5805       48.0   \n",
      "1690         Mineral Sheerscreen Sunscreen SPF 30 PA+++  3.9473       38.0   \n",
      "1691    Mini Mineral Sheerscreen Sunscreen SPF 30 PA+++  3.9473       22.0   \n",
      "\n",
      "      final_score  \n",
      "243      0.506453  \n",
      "1690     0.316841  \n",
      "1691     0.315417  \n"
     ]
    }
   ],
   "source": [
    "top_n = 8\n",
    "recommendations = candidates.sort_values('final_score', ascending=False).head(top_n)\n",
    "\n",
    "# Return relevant columns\n",
    "recommendations = recommendations[\n",
    "    ['product_name', 'rating', 'loves_count', 'price_usd', 'combined_score', 'final_score']\n",
    "]\n",
    "\n",
    "print(recommendations[['product_name', 'rating', 'price_usd', 'final_score']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2b476b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… TF-IDF vectorizer, matrix, and scaler saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save TF-IDF vectorizer and matrix\n",
    "joblib.dump(tfidf, \"tfidf_vectorizer.pkl\")\n",
    "joblib.dump(tfidf_matrix, \"tfidf_matrix.pkl\")\n",
    "\n",
    "# Save the MinMaxScaler\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "print(\"âœ… TF-IDF vectorizer, matrix, and scaler saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1b73abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['skincare_df.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(df, \"skincare_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a10af847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['product_id', 'product_name', 'brand_id', 'brand_name', 'loves_count',\n",
      "       'rating', 'reviews', 'size', 'variation_type', 'variation_value',\n",
      "       'variation_desc', 'ingredients', 'price_usd', 'value_price_usd',\n",
      "       'sale_price_usd', 'limited_edition', 'new', 'online_only',\n",
      "       'out_of_stock', 'sephora_exclusive', 'highlights', 'primary_category',\n",
      "       'secondary_category', 'tertiary_category', 'child_count',\n",
      "       'child_max_price', 'child_min_price', 'primary_category_clean',\n",
      "       'highlights_parsed', 'tertiary_category_clean', 'text_for_tfidf',\n",
      "       'rating_norm', 'popularity_norm', 'combined_score', 'sim_score',\n",
      "       'final_score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "df = joblib.load(\"skincare_df.pkl\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c46dd6",
   "metadata": {},
   "source": [
    "Sentence transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebb8d347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.1.1-py3-none-any.whl (486 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.12.0-cp310-cp310-win_amd64.whl (18.2 MB)\n",
      "Requirement already satisfied: joblib in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.2)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (4.50.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (0.30.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from faiss-cpu) (2.1.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\prana\\appdata\\roaming\\python\\python310\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\prana\\appdata\\roaming\\python\\python310\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: requests in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: networkx in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\prana\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Installing collected packages: joblib, sentence-transformers, faiss-cpu\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.4.2\n",
      "    Uninstalling joblib-1.4.2:\n",
      "      Successfully uninstalled joblib-1.4.2\n",
      "Successfully installed faiss-cpu-1.12.0 joblib-1.5.2 sentence-transformers-5.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# run in a notebook cell (prefix !), or in terminal\n",
    "!pip install -U sentence-transformers faiss-cpu joblib tqdm\n",
    "# If you have GPU and want faiss-gpu, install faiss-gpu accordingly (not shown here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6575af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import joblib\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# If you want to use FAISS\n",
    "import faiss\n",
    "\n",
    "# Choose device: \"cpu\" or \"cuda\" if available\n",
    "DEVICE = \"cpu\"  # change to \"cuda\" if you have GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17e86509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns found in CSV: ['product_id', 'product_name', 'brand_id', 'brand_name', 'loves_count', 'rating', 'reviews', 'size', 'variation_type', 'variation_value', 'variation_desc', 'ingredients', 'price_usd', 'value_price_usd', 'sale_price_usd', 'limited_edition', 'new', 'online_only', 'out_of_stock', 'sephora_exclusive', 'highlights', 'primary_category', 'secondary_category', 'tertiary_category', 'child_count', 'child_max_price', 'child_min_price', 'primary_category_clean', 'highlights_parsed']\n",
      "âœ… Text column created successfully!\n",
      "Number of products: 2003\n",
      "                           product_name  \\\n",
      "0  GENIUS Sleeping Collagen Moisturizer   \n",
      "1          GENIUS Liquid Collagen Serum   \n",
      "\n",
      "                                      text_for_tfidf  \n",
      "0  skincare Moisturizers  Moisturizers  'Vegan', ...  \n",
      "1  skincare Treatments  Face Serums  'Vegan', 'Go...  \n",
      "âœ… DataFrame saved successfully as skincare_df.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(\"skincare_only.csv\")\n",
    "\n",
    "print(\"Columns found in CSV:\", list(df.columns))  # ðŸ‘€ helps confirm whatâ€™s inside\n",
    "\n",
    "# Define helper to safely get columns\n",
    "def safe_get(col):\n",
    "    return df[col].fillna('').astype(str) if col in df.columns else ''\n",
    "\n",
    "# Build unified text column for embeddings/TF-IDF\n",
    "df['text_for_tfidf'] = (\n",
    "    safe_get('primary_category_clean') + ' ' +\n",
    "    safe_get('secondary_category') + ' ' +\n",
    "    safe_get('tertiary_category_clean') + ' ' +\n",
    "    safe_get('tertiary_category') + ' ' +   # backup if clean one missing\n",
    "    safe_get('highlights_parsed') + ' ' +\n",
    "    safe_get('ingredients')\n",
    ").str.replace(r'[\\[\\]]', ' ', regex=True)\n",
    "\n",
    "print(\"âœ… Text column created successfully!\")\n",
    "print(\"Number of products:\", len(df))\n",
    "print(df[['product_name', 'text_for_tfidf']].head(2))\n",
    "\n",
    "# Save for later use\n",
    "joblib.dump(df, \"skincare_df.pkl\")\n",
    "print(\"âœ… DataFrame saved successfully as skincare_df.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecb666d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(MODEL_NAME, device=DEVICE)\n",
    "model.max_seq_length = 512  # safe default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "770b3d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c04e311fe24c3cb04ea67d6402c443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (2003, 384)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sbert_model.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When you have many rows, use batching to avoid OOM\n",
    "texts = df['text_for_tfidf'].astype(str).tolist()\n",
    "batch_size = 64\n",
    "embeddings = []\n",
    "\n",
    "for i in tqdm(range(0, len(texts), batch_size), desc=\"Encoding\"):\n",
    "    batch_texts = texts[i:i+batch_size]\n",
    "    emb = model.encode(batch_texts, convert_to_numpy=True, show_progress_bar=False, device=DEVICE)\n",
    "    embeddings.append(emb)\n",
    "\n",
    "embeddings = np.vstack(embeddings)  # shape: (n_products, dim)\n",
    "\n",
    "# Normalize vectors for cosine search (faiss inner-product on L2-normalized dims)\n",
    "faiss.normalize_L2(embeddings)\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "# Save embeddings array\n",
    "np.save(\"product_embeddings.npy\", embeddings)\n",
    "joblib.dump(embeddings, \"product_embeddings.pkl\")\n",
    "# Save df and model artifacts\n",
    "joblib.dump(df, \"skincare_df.pkl\")\n",
    "joblib.dump(model, \"sbert_model.pkl\")  # optional but useful\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4647a9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f88b147e5c45cbbbff7770ee6af3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SentenceTransformer embeddings & FAISS index saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import faiss\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Load your dataset\n",
    "df = joblib.load(\"skincare_df.pkl\")\n",
    "\n",
    "# Combine all relevant text columns into one\n",
    "df[\"combined_text\"] = (\n",
    "    df[\"primary_category\"].fillna('') + ' ' +\n",
    "    df[\"tertiary_category\"].fillna('') + ' ' +\n",
    "    df[\"highlights_parsed\"].astype(str).fillna('') + ' ' +\n",
    "    df[\"ingredients\"].astype(str).fillna('')\n",
    ")\n",
    "\n",
    "# Load Sentence Transformer\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Encode the dataset\n",
    "embeddings = model.encode(df[\"combined_text\"].tolist(), show_progress_bar=True, convert_to_numpy=True)\n",
    "\n",
    "# Save FAISS index\n",
    "dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dim)  # Inner product (for cosine similarity)\n",
    "faiss.normalize_L2(embeddings)\n",
    "index.add(embeddings)\n",
    "\n",
    "# Save all artifacts\n",
    "faiss.write_index(index, \"skincare_faiss.index\")\n",
    "joblib.dump(df, \"skincare_df.pkl\")\n",
    "model.save(\"sentence_model\")\n",
    "\n",
    "print(\"âœ… SentenceTransformer embeddings & FAISS index saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e9b86cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: [[1.         0.93845505 0.9353634  0.9339823  0.92380285]]\n",
      "Indices: [[   0    4    9 1564  133]]\n"
     ]
    }
   ],
   "source": [
    "# Embeddings must be float32\n",
    "embeddings = embeddings.astype('float32')\n",
    "d = embeddings.shape[1]\n",
    "\n",
    "# We'll use IndexFlatIP (inner product) on normalized vectors -> equivalent to cosine\n",
    "index = faiss.IndexFlatIP(d)\n",
    "index.add(embeddings)  # add vectors\n",
    "\n",
    "# Save index to disk\n",
    "faiss.write_index(index, \"faiss_index.idx\")\n",
    "\n",
    "# Quick sanity check: search top-5 for the first product\n",
    "D, I = index.search(embeddings[:1], k=5)\n",
    "print(\"Distances:\", D)\n",
    "print(\"Indices:\", I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "940b3dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top indices: [1887, 1906, 1874, 1899, 1237]\n",
      "                                           product_name  rating\n",
      "1887       100% Organic Cold-Pressed Moroccan Argan Oil  4.1709\n",
      "1906                  100% Organic Virgin Chia Seed Oil  4.1892\n",
      "1874        100% Organic Cold-Pressed Rose Hip Seed Oil  4.3988\n",
      "1899  Ascorbyl Tetraisopalmitate Solution 20% in Vit...  3.8193\n",
      "1237                      GO OFF Makeup Dissolving Mist  4.1746\n"
     ]
    }
   ],
   "source": [
    "def semantic_search(query_text, top_k=10):\n",
    "    \"\"\"Return top_k product indices sorted by semantic similarity to query_text.\"\"\"\n",
    "    if not query_text or str(query_text).strip()==\"\":\n",
    "        return []\n",
    "    q_emb = model.encode([query_text], convert_to_numpy=True, show_progress_bar=False, device=DEVICE)\n",
    "    faiss.normalize_L2(q_emb)\n",
    "    q_emb = q_emb.astype('float32')\n",
    "    # load index if not in memory\n",
    "    global index\n",
    "    if 'index' not in globals():\n",
    "        index = faiss.read_index(\"faiss_index.idx\")\n",
    "    D, I = index.search(q_emb, k=top_k)\n",
    "    # D are inner product scores (cosine since normalized)\n",
    "    return I[0].tolist(), D[0].tolist()\n",
    "\n",
    "# Example\n",
    "inds, scores = semantic_search(\"vegan sunscreen without parabens for oily skin\", top_k=5)\n",
    "print(\"Top indices:\", inds)\n",
    "print(df.iloc[inds][['product_name','rating']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81d77a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>sim_score</th>\n",
       "      <th>sim_norm</th>\n",
       "      <th>combined_score</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100% Organic Cold-Pressed Moroccan Argan Oil</td>\n",
       "      <td>0.631416</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100% Organic Virgin Chia Seed Oil</td>\n",
       "      <td>0.629203</td>\n",
       "      <td>0.981909</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100% Organic Cold-Pressed Rose Hip Seed Oil</td>\n",
       "      <td>0.615686</td>\n",
       "      <td>0.871433</td>\n",
       "      <td>0</td>\n",
       "      <td>0.610003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ascorbyl Tetraisopalmitate Solution 20% in Vit...</td>\n",
       "      <td>0.615554</td>\n",
       "      <td>0.870357</td>\n",
       "      <td>0</td>\n",
       "      <td>0.609250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GO OFF Makeup Dissolving Mist</td>\n",
       "      <td>0.608894</td>\n",
       "      <td>0.815927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name  sim_score  sim_norm  \\\n",
       "0       100% Organic Cold-Pressed Moroccan Argan Oil   0.631416  1.000000   \n",
       "1                  100% Organic Virgin Chia Seed Oil   0.629203  0.981909   \n",
       "2        100% Organic Cold-Pressed Rose Hip Seed Oil   0.615686  0.871433   \n",
       "3  Ascorbyl Tetraisopalmitate Solution 20% in Vit...   0.615554  0.870357   \n",
       "4                      GO OFF Makeup Dissolving Mist   0.608894  0.815927   \n",
       "\n",
       "   combined_score  final_score  \n",
       "0               0     0.700000  \n",
       "1               0     0.687336  \n",
       "2               0     0.610003  \n",
       "3               0     0.609250  \n",
       "4               0     0.571149  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load artifacts if needed\n",
    "embeddings = joblib.load(\"product_embeddings.pkl\")  # shape (n, dim)\n",
    "df = joblib.load(\"skincare_df.pkl\")\n",
    "# ensure df index aligns with embeddings order (we used df order when computing)\n",
    "assert embeddings.shape[0] == len(df)\n",
    "\n",
    "def get_hybrid_recommendations(query, top_k=50, final_top_n=8, sim_weight=0.7, score_weight=0.3):\n",
    "    # Step 1: semantic top_k using FAISS\n",
    "    inds, sim_scores = semantic_search(query, top_k=top_k)\n",
    "    \n",
    "    # Convert to DataFrame slice\n",
    "    candidates = df.iloc[inds].copy().reset_index(drop=False)  # keep original index in 'index'\n",
    "    # sim_scores are cosine-like in D\n",
    "    candidates['sim_score'] = sim_scores\n",
    "    \n",
    "    # Step 2: normalize sim_score to 0-1\n",
    "    # sim_scores are cosine (range [-1,1]) but here positive due to normalization\n",
    "    # scale to 0-1:\n",
    "    min_s, max_s = candidates['sim_score'].min(), candidates['sim_score'].max()\n",
    "    if max_s - min_s > 1e-6:\n",
    "        candidates['sim_norm'] = (candidates['sim_score'] - min_s) / (max_s - min_s)\n",
    "    else:\n",
    "        candidates['sim_norm'] = 1.0\n",
    "    \n",
    "    # Step 3: ensure we have combined_score in df\n",
    "    if 'combined_score' not in candidates.columns:\n",
    "        # fallback: use rating_norm if exist\n",
    "        candidates['combined_score'] = candidates.get('combined_score', 0)\n",
    "    \n",
    "    # Step 4: hybrid final score\n",
    "    candidates['final_score'] = sim_weight * candidates['sim_norm'] + score_weight * candidates['combined_score']\n",
    "    \n",
    "    # Sort and return top final_top_n\n",
    "    top = candidates.sort_values('final_score', ascending=False).head(final_top_n)\n",
    "    return top\n",
    "\n",
    "# Test\n",
    "top = get_hybrid_recommendations(\"vegan sunscreen without parabens for oily skin\", top_k=100, final_top_n=5)\n",
    "top[['product_name','sim_score','sim_norm','combined_score','final_score']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e917af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model, index, and any arrays that app will load\n",
    "joblib.dump(model, \"sbert_model.pkl\")            # optional, but can load the SBERT model in app (heavy)\n",
    "joblib.dump(df, \"skincare_df.pkl\")\n",
    "joblib.dump(embeddings, \"product_embeddings.pkl\")\n",
    "faiss.write_index(index, \"faiss_index.idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2392000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Files loaded successfully!\n",
      "Dataset size: (2003, 30)\n",
      "Index(['product_id', 'product_name', 'brand_id', 'brand_name', 'loves_count',\n",
      "       'rating', 'reviews', 'size', 'variation_type', 'variation_value',\n",
      "       'variation_desc', 'ingredients', 'price_usd', 'value_price_usd',\n",
      "       'sale_price_usd', 'limited_edition', 'new', 'online_only',\n",
      "       'out_of_stock', 'sephora_exclusive', 'highlights', 'primary_category',\n",
      "       'secondary_category', 'tertiary_category', 'child_count',\n",
      "       'child_max_price', 'child_min_price', 'primary_category_clean',\n",
      "       'highlights_parsed', 'text_for_tfidf'],\n",
      "      dtype='object')\n",
      "\n",
      "ðŸ” Query: oil-free sunscreen for acne-prone skin\n",
      "\n",
      "Top 3 matching products:\n",
      "\n",
      "                                           product_name primary_category  \\\n",
      "243   Full Spectrum 360Âº Refreshing Water Cream Orga...         Skincare   \n",
      "1708  PLAY Antioxidant Body Sunscreen Mist SPF 30 PA...         Skincare   \n",
      "159     Isle Body Oil SPF 30 with Sea Moss and Squalane         Skincare   \n",
      "\n",
      "     tertiary_category  price_usd  rating  similarity_score  \n",
      "243     Face Sunscreen       48.0  4.5805          0.261881  \n",
      "1708    Face Sunscreen       21.0  3.3684          0.250127  \n",
      "159     Body Sunscreen       32.0  4.6000          0.239297  \n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ==============================\n",
    "# ðŸ”¹ Load saved files\n",
    "# ==============================\n",
    "tfidf = joblib.load(\"tfidf_vectorizer.pkl\")\n",
    "tfidf_matrix = joblib.load(\"tfidf_matrix.pkl\")\n",
    "df = joblib.load(\"skincare_df.pkl\")\n",
    "\n",
    "print(\"âœ… Files loaded successfully!\")\n",
    "print(\"Dataset size:\", df.shape)\n",
    "print(df.columns)\n",
    "\n",
    "# ==============================\n",
    "# ðŸ”¹ Example user query\n",
    "# ==============================\n",
    "query = \"oil-free sunscreen for acne-prone skin\"\n",
    "\n",
    "# Convert query into TF-IDF vector\n",
    "query_vec = tfidf.transform([query])\n",
    "\n",
    "# Compute cosine similarity between query and all products\n",
    "cosine_sim = cosine_similarity(query_vec, tfidf_matrix)[0]\n",
    "\n",
    "# Attach similarity scores to dataframe\n",
    "df['similarity_score'] = cosine_sim\n",
    "\n",
    "# Sort by similarity score (descending)\n",
    "top_results = df.sort_values(by='similarity_score', ascending=False).head(3)\n",
    "\n",
    "# Display the top 5 product matches\n",
    "print(\"\\nðŸ” Query:\", query)\n",
    "print(\"\\nTop 3 matching products:\\n\")\n",
    "print(top_results[['product_name', 'primary_category', 'tertiary_category', 'price_usd', 'rating', 'similarity_score']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37602f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Approx Accuracy: 0.950\n",
      "âœ… Approx F1 Score: 0.974\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "df = pd.read_csv(\"skincare_only.csv\")\n",
    "\n",
    "# Prepare text and categories\n",
    "df['text'] = df['primary_category'].fillna('') + \" \" + df['highlights_parsed'].fillna('')\n",
    "sample_df = df.sample(100, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = model.encode(sample_df['text'].tolist(), convert_to_tensor=True)\n",
    "sim_matrix = util.cos_sim(embeddings, embeddings).cpu().numpy()\n",
    "\n",
    "# Build pairs\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "threshold = 0.6  # similarity threshold for \"same category\"\n",
    "\n",
    "for i in range(len(sample_df)):\n",
    "    for j in range(i + 1, len(sample_df)):\n",
    "        same_cat = sample_df.loc[i, 'primary_category'] == sample_df.loc[j, 'primary_category']\n",
    "        true_labels.append(1 if same_cat else 0)\n",
    "        pred_labels.append(1 if sim_matrix[i, j] >= threshold else 0)\n",
    "\n",
    "# Compute metrics\n",
    "acc = accuracy_score(true_labels, pred_labels)\n",
    "f1 = f1_score(true_labels, pred_labels)\n",
    "\n",
    "print(f\"âœ… Approx Accuracy: {acc:.3f}\")\n",
    "print(f\"âœ… Approx F1 Score: {f1:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
